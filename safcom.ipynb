{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 35px;color:white;margin:10;font-size:200%;text-align:center;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://images.pexels.com/photos/7078619/pexels-photo-7078619.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1)\"><b><span style='color:black'><strong>M-Pesa finances tracker RAG(Retrieval Augmented Generation) application </strong></span></b> </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"padding: 20px;color:white;margin:10;font-size:90%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://w0.peakpx.com/wallpaper/957/661/HD-wallpaper-white-marble-white-stone-texture-marble-stone-background-white-stone.jpg)\"><b><span style='color:black'> Problem statement</span></b> </div>\n",
    "\n",
    "In the age of `Generative AI`, there has been a growing application of it called `retrieval Augmented Generation` where one can query their data using natural language processing as if chatting with the documents by asking questions and getting responses. \n",
    "\n",
    "For this project, it involves querying M-Pesa statements and assesing the spending pattern using these applications which vectorizes and embeds the pdf text and stores it into vector databases and a `simple similarity search` is applied to the stored vectors. This helps get the correct response from the documents and stored vectors. \n",
    "\n",
    "## <div style=\"padding: 20px;color:white;margin:10;font-size:90%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://w0.peakpx.com/wallpaper/957/661/HD-wallpaper-white-marble-white-stone-texture-marble-stone-background-white-stone.jpg)\"><b><span style='color:black'> Importing libraries</span></b> </div>\n",
    "\n",
    "The libraries used include:\n",
    "\n",
    "* Llama-index for performing embeddings and referencing llm models\n",
    "* OpenAI for openAI embeddings and converting the queries to vectors\n",
    "* Pypdf for extracting content from the pdf\n",
    "\n",
    "The libraries can be found in the `requirements.txt` file and running the `pip install -r requirements.txt` command in the terminal installs all the required libraries and their respective versions and dependencies. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "load_dotenv()\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "#Allows printing of the response source along with the similarity score. \n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "from llama_parse import LlamaParse\n",
    "import nest_asyncio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> <span style='color:#16C2D5'>|</span> PDF file decryption</b> \n",
    "\n",
    "Since the file is password protrected, decryption of the file is necessary to allow for data extraction uisng the `pypdf` library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decrypting the mpesa statement\n",
    "decrypted_pdf_path = \"Decrypted_MPESA_Statement.pdf\"\n",
    "doc = fitz.open(\"MPESA_Statement_2023-05-28_to_2024-05-28.pdf\")\n",
    "if doc.authenticate(str(598683)):\n",
    "    doc.save(decrypted_pdf_path)\n",
    "else:\n",
    "    raise ValueError(\"Failed to authenticate the PDF with the provided password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After `file decryption`, the next step is loading the `OPENAI_API_KEY` from the environment file for performing embeddings and performing a similarity search for the vectors. \n",
    "\n",
    "The `Python-dotenv library` allows for various methods of loading the environment variables one being the `load_env()` and teh other being using the `config` to get the environment variable values. It is only the `OPENAI-API-KEY` that is stored in the environment file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loand environment variables\n",
    "os.environ['OPENAI_API_KEY'] = config.get(\"OPENAI_API_KEY\")\n",
    "os.environ['LLAMA_CLOUD_API_KEY'] = config.get(\"LLAMA_CLOUD_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\"  # \"markdown\" and \"text\" are available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 2d620a2a-c1eb-476f-81da-6a57ddb47c21\n",
      ".."
     ]
    }
   ],
   "source": [
    "#Use the nest_ascyncio to be able to use the LlamaParser\n",
    "nest_asyncio.apply()\n",
    "file_extractor = {\".pdf\": parser}\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data\", file_extractor=file_extractor).load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the documents into vectors using the `vectorStoreIndex` from `llama-index`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x2bfdead4460>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"padding: 20px;color:white;margin:10;font-size:90%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://w0.peakpx.com/wallpaper/957/661/HD-wallpaper-white-marble-white-stone-texture-marble-stone-background-white-stone.jpg)\"><b><span style='color:black'> Query Engine</span></b> </div>\n",
    "\n",
    "After converting the PDF values to vectors for performing a similarity search, the query engine can now be initiated safely.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"How many days did I make huge withdrawals and what was teh amount withdrawn?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You made a huge withdrawal on July 17, 2023, where you withdrew 6,500.00 units.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint_response(response, show_source=True)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = query_engine.query(\"does my monthly and weekly withdrawals have a pattern?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a pattern in your monthly and weekly withdrawals.\n"
     ]
    }
   ],
   "source": [
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "response3 = query_engine.query(\"How much in total did I withdraw for airtime purchase?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You withdrew a total of 350.00 for airtime purchase.\n"
     ]
    }
   ],
   "source": [
    "print(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response4 = query_engine.query(\"How much was paid in via KCB?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount paid in via KCB was 3,700.00.\n"
     ]
    }
   ],
   "source": [
    "print(response4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "response5 = query_engine.query(\"How much money in total was sent by Michael?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael sent a total of 30.00 + 100.00 = 130.00 in transactions.\n"
     ]
    }
   ],
   "source": [
    "print(response5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "response6 = query_engine.query(\"generate a bar graph of my daily expenditure for the month of january\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can generate a bar graph of your daily expenditure for the month of January by plotting the daily withdrawal amounts from your financial statement data for that specific month.\n"
     ]
    }
   ],
   "source": [
    "print(response6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat-mpesa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
